{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a62f99a2",
   "metadata": {},
   "source": [
    "Author: Mit Gor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6ba9ed4",
   "metadata": {},
   "source": [
    "#### This file contains several tests of methods of applyng textures to an image, in order to use them as part of the final accretion disk image for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install TensorFlow tensorflow_hub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4d050",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae57342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade jax jaxlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc837c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import Image, ImageEnhance, ImageChops\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.image as mpimg_saver\n",
    "\n",
    "\n",
    "import functools\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5306ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is an example of one of the many different coding techniques that were used to experiment with\n",
    "#different textures, effects and texts\n",
    "\n",
    "#loading the original image and the texture image (in this example it is smoke)\n",
    "original_base = Image.open(\"blank_disc (3) (1).jpg\") \n",
    "texture_smoke = Image.open(\"texture5.png\")\n",
    "\n",
    "#here the modes are being converted to match so the image processes can take place without errors\n",
    "if original_base.mode != texture_smoke.mode:\n",
    "    texture_smoke = texture_smoke.convert(original_base.mode)\n",
    "\n",
    "#the texture image is resized to match the original so the effects are enlarged over the whole image\n",
    "texture_smoke = texture_smoke.resize(original_base.size)\n",
    "\n",
    "#stock empty image used to work one same sizes and modes as base\n",
    "new_image = Image.new(original_base.mode, original_base.size, (0, 0, 0))\n",
    "\n",
    "#blending the two images together \n",
    "blend_image = ImageChops.overlay(original_base, texture_smoke)\n",
    "\n",
    "#now the blended image is put over the empty one\n",
    "new_image.paste(blend_image, (0, 0))\n",
    "\n",
    "#these are enhancer factors that were played around and experimented for the best looking final image\n",
    "enhancer = ImageEnhance.Brightness(new_image)\n",
    "\n",
    "#these factors are all dependent on the texture being used\n",
    "new_image = enhancer.enhance(1.2)\n",
    "\n",
    "#for the smoke one the saturation didn't have to be that high but for the saturn ring textures they did etc\n",
    "enhancer = ImageEnhance.Color(new_image)\n",
    "new_image = enhancer.enhance(1.2) #saturation \n",
    "\n",
    "#saving the resulting frame\n",
    "new_image.save(\"new_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106be053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#another example of the various methods on python used to experiment with textures and effects:\n",
    "\n",
    "#here a grayscale wavelength image is being used as the base so the codes specific to these requirements\n",
    "original_img = Image.open('wavelength.jpg').convert('L')\n",
    "#converting the modes to match and corresponding arrays\n",
    "original_img_array = np.array(original_img)\n",
    "\n",
    "#the texture image is loaded and arrays created for image analysis\n",
    "new_texture = Image.open('texture.jpg').convert('RGB')\n",
    "new_texture_array = np.array(new_texture)\n",
    "\n",
    "#the sizes are resized and matched to each other, making sure the heights and widths of the texture is the same\n",
    "height, width = original_img_array.shape\n",
    "#otherwise the texture would only be created on one section of its own size\n",
    "new_texture_resized = new_texture.resize((width, height), resample=Image.Resampling.BILINEAR)\n",
    "#bilinear interpolation used for the resampling experiments here, it interpolates the pixels based on neighbour means\n",
    "#found it to produce better and smoother looking results\n",
    "\n",
    "new_texture_resized_array = np.array(new_texture_resized)\n",
    "\n",
    "\n",
    "#here a mask is made and the numbers are continualously changed based on what sections of the image\n",
    "#the texture should be applied to\n",
    "mask_location = np.zeros_like(new_texture_resized)\n",
    "#texture effect in this example is applied everywhere on the base image \n",
    "mask_location[new_texture_resized_array > 50] = 1\n",
    "\n",
    "#the texture is now blended to the base image\n",
    "alpha = 0.5 \n",
    "#alpha allows the opacity to change which makes the final image more \"blended\" and smoother\n",
    "texture_blend = original_img_array[..., np.newaxis] * (1 - alpha) + new_texture_resized_array * alpha\n",
    "#blending occurs based on the opacity and a final blended array created from the two \n",
    "texture_blend = np.clip(texture_blend, 0, 255) \n",
    "#ensuring the pixel values are within a range(experimented on and changed here and there)\n",
    "\n",
    "#converted to grayscale image by takin mean of the RGB channels \n",
    "output_array = np.mean(texture_blend, axis=2)\n",
    "#final image objects created to be saved \n",
    "final_blended_img = Image.fromarray(np.uint8(output_array))\n",
    "\n",
    "#final image with the texture blended on the original image with improvements made saved\n",
    "final_blended_img.save('output.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4830821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is a code utilising the neural style transfer method\n",
    "#it is not from scratch and is using tutorial code with a module linked below(in hub_handle)\n",
    "\n",
    "\n",
    "#loading the hub being used for the image stylisation\n",
    "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
    "hub_module = hub.load(hub_handle)\n",
    "\n",
    "#function for loading the image taking its path and size (this is same as the one used in the tutorial code)\n",
    "def load_image(path, image_size):\n",
    "    img_saver = tf.io.read_file(path)\n",
    "    #image path read\n",
    "    img_saver = tf.image.decode_jpeg(img_saver, channels=3)\n",
    "    #read as a jpg file and type converted to float\n",
    "    img_saver = tf.image.convert_image_dtype(img_saver, tf.float32)\n",
    "    #resized to the image size\n",
    "    img_saver = tf.image.resize(img_saver, image_size)\n",
    "    return img_saver[tf.newaxis, :]\n",
    "\n",
    "#function for saving the image as a jpg\n",
    "def save_image(image, file_path):\n",
    "    #here the image is scaled to a specific pixel range (ensure the correct stylised image is saved)\n",
    "    image = (image[0] * 255).numpy().astype(np.uint8)\n",
    "    #saved as a jpg \n",
    "    image = Image.fromarray(image)\n",
    "    image.save(file_path, format='JPEG')\n",
    "\n",
    "#the original base image is loaded \n",
    "base_image = 'blank_disc (3) (1).jpg'  \n",
    "#due to GPU limitations the base image can't be as high as our original image thus the resolution greatly reduced\n",
    "#this is then fixed post code and stylisation through enhancing techniques and photoshop\n",
    "#stylisation image also loaded\n",
    "stylisation_texture = 'style.jpg' \n",
    "#size used in hub code but experimented and changed based on images being used\n",
    "image_size= 500  \n",
    "\n",
    "\n",
    "base_image_size = (image_size, image_size)\n",
    "#texture size recommended by hub to stay at 256 but changed depending on whats being worked with\n",
    "texture_size = (256, 256)  \n",
    "\n",
    "#the base image is loaded using the function\n",
    "blended_image2 = load_image(base_image, base_image_size)\n",
    "#same for stylised image\n",
    "stylised_image = load_image(stylisation_texture, texture_size)\n",
    "\n",
    "\n",
    "#average pooling performed to smooth any small variations\n",
    "#however this reduces the resolution thus effects and photoshop needed to enhance final image \n",
    "stylised_image = tf.nn.avg_pool(stylised_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
    "\n",
    "\n",
    "#final image tensor made by passing the inputs in the module here the acutal stylisation takes place\n",
    "final_image = hub_module(tf.constant(blended_image2), tf.constant(stylised_image))\n",
    "\n",
    "#in the module the gram matrices and equations is calculated for the style and then the stylisation is produced and optimised\n",
    "#it then returns the stylised image that will be saved\n",
    "\n",
    "stylized_image = final_image[0]\n",
    "#extracted with [0] due to tensor containing optimisation loss as well\n",
    "\n",
    "\n",
    "#here are some post processing techniques that were applied to the final image for experimenting\n",
    "stylized_image = tf.image.adjust_brightness(stylized_image, delta=0.3)\n",
    "#mainly used photoshop to change these instead\n",
    "#since they produced better results and features such as sharpness were not available\n",
    "stylized_image = tf.image.adjust_contrast(stylized_image, contrast_factor=1.5)\n",
    "stylized_image = tf.image.adjust_saturation(stylized_image, saturation_factor=1.5)\n",
    "\n",
    "\n",
    "#image converted to array\n",
    "img_saver = np.array(stylized_image[0])\n",
    "#pixel vals clipped to 0-255\n",
    "img_saver = tf.clip_by_value(img_saver, 0, 255)\n",
    "#uint data conversion\n",
    "img_saver = np.uint8(img_saver.numpy())\n",
    "\n",
    "#final styalised image saved:\n",
    "save_image(stylized_image, 'stylized_image.jpg')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ff435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
